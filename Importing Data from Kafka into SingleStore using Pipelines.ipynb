{
  "cells": [
    {
      "id": "3b02d847",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-header\" style=\"display: flex; background-color: rgba(235, 249, 245, 0.25); padding: 5px;\"\u003e\n    \u003cdiv id=\"icon-image\" style=\"width: 90px; height: 90px;\"\u003e\n        \u003cimg width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/database.png\" /\u003e\n    \u003c/div\u003e\n    \u003cdiv id=\"text\" style=\"padding: 5px; margin-left: 10px;\"\u003e\n        \u003cdiv id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\"\u003eSingleStore Notebooks\u003c/div\u003e\n        \u003ch1 style=\"font-weight: 500; margin: 8px 0 0 4px;\"\u003eImporting Data from Kafka into SingleStore using Pipelines\u003c/h1\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "46a1d738",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eInput Credentials\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003eDefine the \u003cb\u003eBOOTSTRAP_SERVER\u003c/b\u003e, \u003cb\u003ePORT\u003c/b\u003e, \u003cb\u003eTOPIC\u003c/b\u003e,\u003cb\u003eSASL_USERNAME\u003c/b\u003e,\u003cb\u003eSASL_MECHANISM\u003c/b\u003e,\u003cb\u003eSECURITY_PROTOCOL\u003c/b\u003e, and \u003cb\u003eSASL_PASSWORD\u003c/b\u003e variables below for integration, replacing the placeholder values with your own.\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "88b1ac9d",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "BOOTSTRAP_SERVER = 'bootstrap-server-url'\nPORT = kafka-broker-port\nTOPIC = 'kafka-topic'\nSASL_USERNAME = 'username'\nSASL_MECHANISM = 'sasl-mechanism'\nSECURITY_PROTOCOL = 'security-proptocol'\nSASL_PASSWORD = 'password'",
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "64fdd646",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "This notebook demonstrates how to create a sample table in SingleStore, set up a pipeline to import data from Kafka Topic, and run queries on the imported data. It is designed for users who want to integrate Kafka data with SingleStore and explore the capabilities of pipelines for efficient data ingestion.",
      "attachments": {}
    },
    {
      "id": "c35b30d7",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003ch3\u003ePipeline Flow Illustration\u003c/h3\u003e",
      "attachments": {}
    },
    {
      "id": "979e53c2",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cimg src=https://singlestoreloaddata.s3.ap-south-1.amazonaws.com/images/LoadDataKafka.png width=\"100%\" hight=\"50%\"/\u003e",
      "attachments": {}
    },
    {
      "id": "9f9d6aa2",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "##  Creating Table in SingleStore\n\nStart by creating a table that will hold the data imported from Kafka.",
      "attachments": {}
    },
    {
      "id": "82a48dd0",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\n/* Feel free to change table name and schema */\n\nCREATE TABLE IF NOT EXISTS my_table (\n    id INT,\n    name VARCHAR(255),\n    age INT,\n    address TEXT\n);",
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "90ad124f",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## Create a Pipeline to Import Data from Kafka\n\nYou'll need to create a pipeline that pulls data from Kafka topic into this table. This example assumes you have a JSON Message in your Kakfa topic.\n\n\u003ci\u003eEnsure that:\nYou have access to the Kafka topic.\nProper IAM roles or access keys are configured in SingleStore.\nThe JSON message has a structure that matches the table schema.\u003c/i\u003e",
      "attachments": {}
    },
    {
      "id": "6e401f87",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Using these identifiers and keys, execute the following statement.",
      "attachments": {}
    },
    {
      "id": "0b4f42d6",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nCREATE OR REPLACE PIPELINE kafka_import_pipeline AS LOAD DATA KAFKA '{{BOOTSTRAP_SERVER}}:{{PORT}}/{{TOPIC}}'\nCONFIG '{\n  \"sasl.username\": \"{{SASL_USERNAME}}\",\n  \"sasl.mechanism\": \"{{SASL_MECHANISM}}\",\n  \"security.protocol\": \"{{SECURITY_PROTOCOL}}\",\n  \"ssl.ca.location\": \"/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\"\n}'\nCREDENTIALS '{\n  \"sasl.password\": \"{{SASL_PASSWORD}}\"\n}'\nINTO TABLE my_table\nFORMAT JSON ;",
      "outputs": [],
      "execution_count": 3
    },
    {
      "id": "1d137801",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## Start the Pipeline\n\nTo start the pipeline and begin importing the data from the Kafka topic:",
      "attachments": {}
    },
    {
      "id": "e94cff73",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nSTART PIPELINE kafka_import_pipeline;",
      "outputs": [],
      "execution_count": 4
    },
    {
      "id": "a41c3fcc",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "You can see status of your pipeline \u003ca href='https://portal.singlestore.com/organizations/org-id/pipelines'\u003e Click Here\u003c/a\u003e",
      "attachments": {}
    },
    {
      "id": "094b857c",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## Select Data from the Table\n\nOnce the data has been imported, you can run a query to select it:",
      "attachments": {}
    },
    {
      "id": "bc0f7b0c",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nSELECT * FROM my_table LIMIT 10;",
      "outputs": [],
      "execution_count": 5
    },
    {
      "id": "669dac71",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "### Check if all data of the data is loaded",
      "attachments": {}
    },
    {
      "id": "a47c2f0f",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nSELECT count(*) FROM my_table",
      "outputs": [],
      "execution_count": 6
    },
    {
      "id": "91eae728",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## Conclusion\n\nWe have shown how to insert data from a Kafka topic using `Pipelines` to SingleStoreDB. These techniques should enable you to\nintegrate your Kafka topic with SingleStoreDB.",
      "attachments": {}
    },
    {
      "id": "6dc86514",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## Clean up\n\nRemove the '#' to uncomment and execute the queries below to clean up the pipeline and table created.",
      "attachments": {}
    },
    {
      "id": "706ccd4c",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "#### Drop Pipeline",
      "attachments": {}
    },
    {
      "id": "ed7dc33a",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\n#STOP PIPELINE kafka_import_pipeline;\n\n#DROP PIPELINE kafka_import_pipeline;",
      "outputs": [],
      "execution_count": 7
    },
    {
      "id": "b5e15411",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "#### Drop Data",
      "attachments": {}
    },
    {
      "id": "f8f3d6ef",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\n#DROP TABLE my_table;",
      "outputs": [],
      "execution_count": 8
    },
    {
      "id": "12d50a52",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"\u003e\u003c/div\u003e\n\u003cdiv\u003e\u003cimg src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/\u003e\u003c/div\u003e",
      "attachments": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimeType": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "jupyterlab": {
      "notebooks": {
        "version_major": 6,
        "version_minor": 4
      }
    },
    "singlestore_connection": {
      "connectionID": "",
      "defaultDatabase": ""
    },
    "singlestore_cell_default_language": "python",
    "singlestore_row_limit": 300
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
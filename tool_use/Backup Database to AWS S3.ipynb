{
  "cells": [
    {
      "id": "94965d32",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-header\" style=\"display: flex; background-color: rgba(235, 249, 245, 0.25); padding: 5px;\"\u003e\n    \u003cdiv id=\"icon-image\" style=\"width: 90px; height: 90px;\"\u003e\n        \u003cimg width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/database.png\" /\u003e\n    \u003c/div\u003e\n    \u003cdiv id=\"text\" style=\"padding: 5px; margin-left: 10px;\"\u003e\n        \u003cdiv id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\"\u003eSingleStore Notebooks\u003c/div\u003e\n        \u003ch1 style=\"font-weight: 500; margin: 8px 0 0 4px;\"\u003eBackup Database to AWS S3\u003c/h1\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "6992694c",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\n## Intro\n\n\u003cp class=\"has-text-justified\"\u003e\n    Introducing a powerful Python notebook designed to simplify performing database backups on schedule\n\u003c/p\u003e\n\n## What you will learn in this notebook:\n\n1. How to backup database to AWS S3 [SQL]\n\n## What benefits do you get out of using the notebook.\n\n1. This notebook explains how we use SingleStore secrets feature to provide the configuration parameters we can control backup process (either full or incremental) in scheduled environment\n\n\n## Questions?\n\nReach out to us through our [forum](https://www.singlestore.com/forum).",
      "attachments": {}
    },
    {
      "id": "209dd4f5",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "### Pre-requisites\n\nWe will need below parameters to proceed.\n\n\u003col type=\"A\"\u003e\n    \u003cli\u003eTo access AWS S3, we need AWS Access key ID,AWS Secret access key, Aws Session Token\u003c/li\u003e\n    \u003cli\u003eDatabase User should have 'BACKUP', 'OUTBOUND', 'PROCESS' grant\u003c/li\u003e\n    \u003cli\u003eS3 Path provided should not exist [ bucket should exists, remaining path will be created if not existing for initial backup]\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eNote: \u003c/p\u003e\n\n\u003col\u003e\n    \u003cli\u003echeck user grants by running 'show grants'.\u003c/li\u003e\n    \u003cli\u003eS3 Path if not exists, will be created by singlestore.\u003c/li\u003e\n    \u003cli\u003eGeneral format is 'database_name.backup'.    \u003c/li\u003e\n    \u003cli\u003eAWS IAM user should have S3 read,  \u0026nbsp; write access\u003c/li\u003e\n\u003c/ol\u003e",
      "attachments": {}
    },
    {
      "id": "ac58f380",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "### Imports",
      "attachments": {}
    },
    {
      "id": "61bab745",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import io\nimport logging\nimport time\nimport getpass\n\nimport singlestoredb as s2\nfrom IPython.display import display, HTML",
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "471c7717",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "### Variables",
      "attachments": {}
    },
    {
      "id": "8652cd49",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "aws_key_id = None\naws_secret_key = None\naws_region = 'us-east-1'\ns3_target_path = None\naws_session_token = None\nis_incremental_backup = 'N'",
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "9e661147",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "### Functions to display various alerts",
      "attachments": {}
    },
    {
      "id": "d100faff",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "def show_warn(warn_msg):\n    \"\"\"\n    Display a warning message in a formatted HTML alert box.\n\n    Parameters\n    ----------\n    warn_msg : str\n        The warning message to display.\n    \"\"\"\n    display(HTML(f'''\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eAction Required\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003e{warn_msg}\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e'''))\n\ndef show_error(error_msg):\n    \"\"\"\n    Display an error message in a formatted HTML alert box.\n\n    Parameters\n    ----------\n    error_msg : str\n        The error message to display.\n    \"\"\"\n    display(HTML(f'''\u003cdiv class=\"alert alert-block alert-danger\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-triangle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eError\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003e{error_msg}\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e'''))\n\n\ndef show_success(success_msg):\n    \"\"\"\n    Display a success message in a formatted HTML alert box.\n\n    Parameters\n    ----------\n    success_msg : str\n        The success message to display.\n    \"\"\"\n    display(HTML(f'''\u003cdiv class=\"alert alert-block alert-success\"\u003e\n    \u003cb class=\"fa fa-solid fa-check-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eSuccess\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003e{success_msg}\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e'''))",
      "outputs": [],
      "execution_count": 3
    },
    {
      "id": "44d05387",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "### LogControl",
      "attachments": {}
    },
    {
      "id": "bdfe6e78",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "**Note**\n\nTo enable logs\n\n - Modify 'enable_debug_log(False)' to 'enable_debug_log(True)' in code below",
      "attachments": {}
    },
    {
      "id": "ebe1585e",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "def enable_debug_log(enabled):\n    if enabled:\n        logging.getLogger().setLevel(logging.DEBUG)\n    else:\n        logging.getLogger().setLevel(logging.ERROR)",
      "outputs": [],
      "execution_count": 4
    },
    {
      "id": "021a7ca2",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "### Utility functions for handling S3 PATHs, SQL Statement, backup",
      "attachments": {}
    },
    {
      "id": "60f2787b",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "def get_bkp_path(s3_path, db_name, do_increment):\n    \"\"\"\n    Get the backup path based on the type of backup (incremental or initial).\n\n    Parameters\n    ----------\n    s3_path : str\n        The base S3 path for backups.\n    db_name : str\n        The name of the database.\n    do_increment: str\n        'Y' for incremental backup, else Full Backup\n\n    Returns\n    -------\n    str\n        The final backup path.\n\n    \"\"\"\n    if do_increment == 'Y':\n        logging.info('Is an incremental backup, will use exact path')\n        return s3_path\n    else:\n        logging.info('Is an initial backup, will use time appended path')\n        t = time.localtime(time.time())\n        my_path = f'{s3_path}/{db_name}/{t.tm_year}-{t.tm_mon:02d}-{t.tm_mday:02d}/{t.tm_hour:02d}{t.tm_min:02d}{t.tm_sec:02d}/'\n        logging.info(f'Backup Path : {my_path}')\n        print(f'Backup Path : {my_path}')\n        return my_path\n\n\n\ndef get_sql_statement(db_name_to_bkp, is_incremental_backup):\n    \"\"\"\n    Get the SQL statement for backing up a database.\n\n    Parameters\n    ----------\n    db_name_to_bkp : str\n        The name of the database to backup.\n    is_incremental_backup : str\n        is incremental backup.\n\n    Returns\n    -------\n    str\n        The SQL statement for backup.\n\n    \"\"\"\n    global aws_key_id, aws_secret_key, aws_region, s3_target_path, aws_session_token\n    aws_key_id = (input('Enter AWS_API_KEY_ID:') if aws_key_id == None else aws_key_id)\n    aws_secret_key = (getpass.getpass('Enter AWS_API_SECRET:') if aws_secret_key == None else aws_secret_key)\n    aws_region = (input('Enter AWS_REGION:') if aws_region == None else aws_region)\n    s3_target_path = (input('Enter AWS S3 Path:') if s3_target_path == None else s3_target_path)\n    aws_session_token = (input('Enter AWS_SESSION_TOKEN:') if aws_session_token == None else aws_session_token)\n\n    data = io.StringIO()\n    data.write('BACKUP DATABASE ' + db_name_to_bkp + ' ')\n    if is_incremental_backup == 'Y':\n        data.write(' WITH DIFFERENTIAL ')\n    else:\n        data.write(' WITH INIT ')\n    data.write(' TO S3 \"' + get_bkp_path(s3_target_path, db_name_to_bkp, is_incremental_backup) + '\" ')\n    data.write(' CONFIG \\'{\"region\":\"' + aws_region + '\"}\\'')\n    data.write(' CREDENTIALS \\'{\"aws_access_key_id\":\"' + aws_key_id\n               + '\",\"aws_secret_access_key\":\"' + aws_secret_key + '\"' )\n    if aws_session_token != '':\n        data.write(', \"aws_session_token\":\"' + aws_session_token + '\" ')\n\n    data.write('}\\' ')\n    logging.debug(f'statement: {data.getvalue()}')\n    return data.getvalue()\n\n\ndef perform_backup(my_cursor, curr_db_name, do_incremental):\n    \"\"\"\n    Perform a database backup.\n\n    Parameters\n    ----------\n    my_cursor : cursor\n        The database cursor.\n    curr_db_name : str\n        The name of the database to backup.\n    do_incremental: str\n        'Y' to perform incremental backup\n\n    \"\"\"\n    logging.debug(f'backing up db {curr_db_name}')\n    my_cursor.execute(get_sql_statement(curr_db_name, do_incremental))\n    results = cursor.fetchall()\n    if results is None:\n        logging.error('Backup execution failed')\n    else:\n        logging.info(\"Backup completed\")",
      "outputs": [],
      "execution_count": 5
    },
    {
      "id": "bf821c9a",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "enable_debug_log(True)\nprint(connection_url)\ntry:\n    if connection_url.endswith('/') or connection_url.endswith('information_schema'):\n        #Hanlde case when database not selected or information_schema selected\n        #Connect to information schema and backup all databases\n        logging.debug('No database selected, will use information_schema and back up all databases')\n        my_db_url = connection_url\n        if connection_url.endswith('/'):\n            my_db_url = my_db_url + 'information_schema'\n            logging.debug(f'connection url updated {my_db_url}')\n\n        conn = s2.connect(my_db_url, results_type='dict')\n        with conn.cursor() as cursor:\n            # Get a list of databases to backup\n            cursor.execute(\n                \"SELECT schema_name FROM information_schema.schemata WHERE  schema_name NOT IN ( 'cluster', 'memsql', 'information_schema' );\")\n            for row in cursor.fetchall():\n                logging.debug(f\"processing db {row['schema_name']}\")\n                # Backup each database\n                perform_backup(my_cursor=cursor, curr_db_name=row['schema_name'], do_incremental='N')\n                logging.debug(f\"processing db {row['schema_name']} complete\")\n\n    else:\n            #Connect to selected database and take its backup\n            database_to_bkp = connection_url.split('/')[-1]\n\n            # Establish a connection to the database\n            conn = s2.connect(results_type='dict')\n            with conn.cursor() as cursor:\n                perform_backup(my_cursor=cursor, curr_db_name=database_to_bkp, do_incremental=is_incremental_backup)\n\n            show_success('Backup Process Completed')\n\nexcept s2.exceptions.OperationalError as ope:\n    # Handle specific operational errors\n    if 'NoSuchBucket' in ope.errmsg:\n        logging.error('Provided S3 Bucket does not exist. Please check.')\n        show_error('Provided S3 Bucket does not exist. Please check.')\n    elif 'Access denied' in ope.errmsg:\n        logging.error('Failed to backup due to missing grants or firewall settings. Please check.')\n        show_error('Failed to backup due to missing grants or firewall settings. Please check.')\n    else:\n        logging.error(f'Failed. Error message: {ope.errmsg}')\n        show_error(f'Failed to backup. {ope.errmsg}')\nexcept s2.Error as e:\n    # Handle any other errors\n    print(f'Encountered exception {e}')\n    logging.exception(e)\n    show_error(f'Failed to backup. {str(e)}')\n\nprint('\\n\\nScript execution completed')",
      "outputs": [],
      "execution_count": 6
    },
    {
      "id": "8fea5794",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "### Verify Result\n\nIf script executed without errors. please check the S3 bucket for uploaded files ( Backup Path is printed to console )\n\nGeneral format is 'database_name.backup' or 'database_name.incr_backup'.\n\nYou may use below query to check backups created ( apply filter to limit data as per your needs )\n\n    select * from information_schema.MV_BACKUP_HISTORY",
      "attachments": {}
    },
    {
      "id": "6e27e49b",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "**Important Note**\n\n- To use this as scheduled notebook, we have to modify to read configuration data from table instead of user input",
      "attachments": {}
    },
    {
      "id": "8a2988ca",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"\u003e\u003c/div\u003e\n\u003cdiv\u003e\u003cimg src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/\u003e\u003c/div\u003e",
      "attachments": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimeType": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "singlestore_connection": {
      "connectionID": "",
      "defaultDatabase": ""
    },
    "singlestore_cell_default_language": "python",
    "singlestore_row_limit": 300
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
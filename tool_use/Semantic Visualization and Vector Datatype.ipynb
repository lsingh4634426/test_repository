{
  "cells": [
    {
      "id": "26367f5e",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-header\" style=\"display: flex; background-color: rgba(210, 255, 153, 0.25); padding: 5px;\"\u003e\n    \u003cdiv id=\"icon-image\" style=\"width: 90px; height: 90px;\"\u003e\n        \u003cimg width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/chart-network.png\" /\u003e\n    \u003c/div\u003e\n    \u003cdiv id=\"text\" style=\"padding: 5px; margin-left: 10px;\"\u003e\n        \u003cdiv id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\"\u003eSingleStore Notebooks\u003c/div\u003e\n        \u003ch1 style=\"font-weight: 500; margin: 8px 0 0 4px;\"\u003eSemantic Visualization and Vector Datatype\u003c/h1\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "8abb8215",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eNote\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003eThis notebook can be run on a Free Starter Workspace. To create a Free Starter Workspace navigate to \u003ctt\u003eStart\u003c/tt\u003e using the left nav. You can also use your existing Standard or Premium workspace with this Notebook.\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "66c2ea71",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\nSingleStoreDB supports vector database processing, which allows you to store and search vector data.\nVectors usually come from objects: text, images, video, audio, etc.\nIn a vector space model, words with similar meanings, such as \u003ci\u003e\"happy\"\u003c/i\u003e and \u003ci\u003e\"joyful,\"\u003c/i\u003e are represented by vectors that lie in proximity, reflecting their semantic similarity.\nVector database searches find data based on its content or meaning, even without exact matches.",
      "attachments": {}
    },
    {
      "id": "c1efbe85",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 1. Create a workspace in your workspace group\n\nS-00 is sufficient.\n\n## 2. Create a database named `db_vector`",
      "attachments": {}
    },
    {
      "id": "834d7507",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eAction Required\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003e If you have a Free Starter Workspace deployed already, select the database from drop-down menu at the top of this notebook. It updates the \u003ctt\u003econnection_url\u003c/tt\u003e to connect to that database.\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "1d6d455c",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "shared_tier_check = %sql show variables like 'is_shared_tier'\nif not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n    %sql DROP DATABASE IF EXISTS db_vector;\n    %sql CREATE DATABASE db_vector;",
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "180f3641",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eAction Required\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003e Make sure to select a database from the drop-down menu at the top of this notebook. It updates the \u003ctt\u003econnection_url\u003c/tt\u003e  to connect to that database.\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "aa7a4a14",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Create table `words` and insert the words into the table.",
      "attachments": {}
    },
    {
      "id": "e1d38b42",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nCREATE TABLE /* Creating table for sample data. */ words(word varchar(25));\n\nINSERT INTO words VALUES (\"red\"), (\"potatoes\"), (\"soda\"), (\"cheese\"),\n                         (\"water\"), (\"blue\"), (\"crispy\"), (\"hamburger\"),\n                         (\"coffee\"), (\"green\"), (\"milk\"), (\"la croix\"),\n                         (\"yellow\"), (\"chocolate\"), (\"french fries\"),\n                         (\"latte\"), (\"cake\"), (\"brown\"), (\"cheeseburger\"),\n                         (\"espresso\"), (\"cheesecake\"), (\"black\"), (\"mocha\"),\n                         (\"fizzy\"), (\"carbon\"), (\"banana\"), (\"sunshine\"),\n                         (\"orange carrot\"), (\"sun\"), (\"hay\"), (\"cookies\"),\n                         (\"fish\"), ('king'), ('man'), ('woman'), ('queen'),\n                         ('Paris'), ('France'), ('Poland'), ('Warsaw'),\n                         ('prince'), ('throne'), ('Elizabeth'), ('ruler');",
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "7cfb0013",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nSHOW TABLES EXTENDED;",
      "outputs": [],
      "execution_count": 3
    },
    {
      "id": "5818d73b",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 3. Install and import required libraries\nIn this section, we will set up the necessary environment by installing important libraries .\n\nThe install process may take a couple minutes.",
      "attachments": {}
    },
    {
      "id": "6c5421e5",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "!pip3 install --upgrade sentence-transformers torch tensorflow pandarallel --quiet",
      "outputs": [],
      "execution_count": 4
    },
    {
      "id": "b83a712d",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Import several libraries for data manipulation (e.g., Pandas, NumPy), database connectivity (SQLAlchemy, SingleStoreDB), machine learning (PyTorch, Transformers), and parallel processing (pandarallel).",
      "attachments": {}
    },
    {
      "id": "1e03f1e3",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import json\nimport ibis\nimport numpy as np\nimport pandas as pd\nimport sqlalchemy as sa\nimport singlestoredb as s2\nimport torch\nfrom pandarallel import pandarallel\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom sqlalchemy import *\ndb_connection = create_engine(connection_url)\npandarallel.initialize(nb_workers=2, progress_bar=True)",
      "outputs": [],
      "execution_count": 5
    },
    {
      "id": "5edb77c5",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 4. Load Sentence Transformer model along with its tokenizer, making them ready for use in tasks like sentence embeddings or similarity calculations.",
      "attachments": {}
    },
    {
      "id": "b82fecbf",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Load Sentence Transformers model",
      "attachments": {}
    },
    {
      "id": "07ce4e31",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n\nmodel = AutoModel.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)",
      "outputs": [],
      "execution_count": 6
    },
    {
      "id": "ddef8850",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 5. Load the data into dataframe from database table",
      "attachments": {}
    },
    {
      "id": "8b410662",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Load the data into a DataFrame",
      "attachments": {}
    },
    {
      "id": "cbef4bf7",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "result = %sql  select * from words;\n\ndf = pd.DataFrame(result)\ndf",
      "outputs": [],
      "execution_count": 7
    },
    {
      "id": "a4d048d4",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 6. Function to retrieve the embedding\n\nThis function, named get_embedding, takes a \u003cb\u003esentence\u003c/b\u003e as input and returns its \u003cb\u003eembedding\u003c/b\u003e using a pre-trained tokenizer and model. It tokenizes the sentence and returns the resulting embedding as a NumPy array with a float32 data type.",
      "attachments": {}
    },
    {
      "id": "08dc6881",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import numpy as np\n\ndef get_embedding(sentence: str) -\u003e np.ndarray[np.float32]:\n    \"\"\"Retrieve embedding for given sentence.\"\"\"\n    inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\")\n    with torch.no_grad():\n        embedding = model(**inputs).last_hidden_state.mean(dim=1).squeeze().tolist()\n    return np.array(embedding, dtype='\u003cf4')",
      "outputs": [],
      "execution_count": 8
    },
    {
      "id": "1d0547af",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 7. Apply the function `get_embedding`\n\nIt adds a new column 'word_embeddings' to a DataFrame df by applying a function get_embedding in parallel to the 'word' column, aiming to calculate and store word embeddings for each word in the DataFrame. The parallel_apply function  leverages parallel processing capabilities for efficient computation.",
      "attachments": {}
    },
    {
      "id": "946f640e",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "# Apply the function\ndf['word_embeddings'] = df['word'].parallel_apply(get_embedding)",
      "outputs": [],
      "execution_count": 9
    },
    {
      "id": "b99a81a7",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Below code writes the DataFrame df to a SQL table named `words_table` using SingleStoreDB (s2). It replaces the existing table if it already exists, does not include an index column in the table, and specifies the data type for the `word_embeddings` column as LargeBinary.",
      "attachments": {}
    },
    {
      "id": "778e76ad",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "# Create the table with vector embeddings\ndf.to_sql(\n    'words_table',\n    s2.create_engine().connect(),\n    if_exists='replace',\n    index=False,\n    dtype=dict(word_embeddings=sa.LargeBinary),\n)",
      "outputs": [],
      "execution_count": 10
    },
    {
      "id": "e78a01a2",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 8. Visualizing words\nBelow code transforms word embeddings stored in the `word_embeddings` column of DataFrame df using t-SNE (t-Distributed Stochastic Neighbor Embedding), reducing the dimensionality to 2 components. The resulting transformed data is stored in the variable `vis_dims`, representing the two-dimensional visualization of the word embeddings.",
      "attachments": {}
    },
    {
      "id": "346ea3c9",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "matrix = df[\"word_embeddings\"]\nmatrix = matrix.tolist()\nmatrix",
      "outputs": [],
      "execution_count": 11
    },
    {
      "id": "583e7119",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "matrix = np.asarray(matrix)\n\nfrom sklearn.manifold import TSNE\n\n# Create a t-SNE model and transform the data\ntsne = TSNE(n_components=2, perplexity=10, random_state=42, init='random', learning_rate=200)\nvis_dims = tsne.fit_transform(matrix)\nvis_dims.shape",
      "outputs": [],
      "execution_count": 12
    },
    {
      "id": "3ef02f0e",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Install the Matplotlib library using the pip package manager, allowing for the visualization of data and plots in Python.",
      "attachments": {}
    },
    {
      "id": "90afcd01",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "!pip install matplotlib",
      "outputs": [],
      "execution_count": 13
    },
    {
      "id": "dd14cc00",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Using Matplotlib to create a scatter plot visualizing the 2D representation of word embeddings obtained from t-SNE. The code iterates through each word in the DataFrame df, extracts its coordinates from vis_dims, and annotates the corresponding point on the scatter plot with the word label. Finally, the plot is displayed using `plt.show()`.",
      "attachments": {}
    },
    {
      "id": "f3394b79",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\n\nlabels = []\nx = [x for x,y in vis_dims]\ny = [y for x,y in vis_dims]\nfor word in range(len(df)):\n    first_value = df['word'].iat[word]\n    labels.append(first_value)\n\nprint(len(df))\n\nplt.scatter(x, y,alpha=0.3)\n\nfor i in range(len(x)):\n    plt.scatter(x[i],y[i])\n    plt.annotate(\n        labels[i],\n        xy=(x[i], y[i]),\n        xytext=(5, 2),\n        textcoords='offset points',\n        ha='right',\n        va='bottom',\n    )\n\nplt.show();",
      "outputs": [],
      "execution_count": 14
    },
    {
      "id": "dc848797",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "You can insert words of your choice in the \u003ci\u003e  words \u003c/i\u003e table  and execute all the cells above to visualize the semantic patterns.",
      "attachments": {}
    },
    {
      "id": "d37f2217",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 9. Introducing Vector Datatype",
      "attachments": {}
    },
    {
      "id": "99cd0b59",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "We can see below `word_embeddings` column is `blob` datatype",
      "attachments": {}
    },
    {
      "id": "8f0eebf9",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nDESC words_table;",
      "outputs": [],
      "execution_count": 15
    },
    {
      "id": "fa8d1ec0",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nSELECT word, word_embeddings FROM words_table LIMIT 2;",
      "outputs": [],
      "execution_count": 16
    },
    {
      "id": "be1a5e6a",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "This below line of code executes a SQL query on the `words_table`, selecting the `word` column and the hexadecimal representation of the `word_embeddings` column for the first row in the table using the `limit 1` clause.",
      "attachments": {}
    },
    {
      "id": "60689524",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nSELECT word, HEX(word_embeddings) FROM words_table LIMIT 1;",
      "outputs": [],
      "execution_count": 17
    },
    {
      "id": "508faddf",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Below query extracts the `word` column and unpacks the JSON array stored in the `word_embeddings` column for the first row in the `words_table`, providing a more readable representation of the word embeddings.",
      "attachments": {}
    },
    {
      "id": "d3fa6534",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nSELECT word, JSON_ARRAY_UNPACK(word_embeddings) FROM words_table LIMIT 1;",
      "outputs": [],
      "execution_count": 18
    },
    {
      "id": "ca8ad8bd",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 10. Transition from BLOB to Vector datatype\n\n\u003cp\u003e 1. Add a new vector column to the right of the blob column.\u003c/p\u003e\n\u003cp\u003e 2. Update the vector column with the data from the blob column.\u003c/p\u003e\n\u003cp\u003e 3. Drop the blob column.\u003c/p\u003e\n\u003cp\u003e 4. Rename the new vector column to the old blob column name. This will ensure any previous queries will still work, or at least require fewer changes.\n\u003c/p\u003e",
      "attachments": {}
    },
    {
      "id": "f6e449f9",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nSELECT VECTOR_NUM_ELEMENTS(word_embeddings) FROM words_table LIMIT 1;",
      "outputs": [],
      "execution_count": 19
    },
    {
      "id": "d58eefb6",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nALTER TABLE words_table ADD COLUMN emb2 vector(384) AFTER word_embeddings;\nUPDATE words_table SET emb2=word_embeddings;",
      "outputs": [],
      "execution_count": 20
    },
    {
      "id": "d40fe9ce",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nSELECT word, emb2, JSON_ARRAY_UNPACK(word_embeddings) FROM words_table LIMIT 1;",
      "outputs": [],
      "execution_count": 21
    },
    {
      "id": "5bffb8aa",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nALTER TABLE words_table DROP COLUMN word_embeddings;\nALTER TABLE words_table CHANGE emb2 word_embeddings;",
      "outputs": [],
      "execution_count": 22
    },
    {
      "id": "60a3d4bd",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nDESC words_table;",
      "outputs": [],
      "execution_count": 23
    },
    {
      "id": "02364df2",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 11. Semantic Search of the word -sunshine \u0026#127774; using Infix Operator\n\nPerforming a semantic search for the word 'sunshine' to find contextually similar or related words and phrases based on their semantic meanings rather than exact lexical matches.\n\nThe infix operators `\u003c*\u003e` and `\u003c-\u003e` can be used to  facilitate DOT_PRODUCT and EUCLIDEAN_DISTANCE operations, respectively, providing a more concise query syntax compared to using the existing built-in functions such as DOT_PRODUCT(a, b) and EUCLIDEAN_DISTANCE(a, b).",
      "attachments": {}
    },
    {
      "id": "98a39ef5",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nSELECT word_embeddings INTO @c from words_table WHERE word LIKE 'sunshine%';\nSELECT word, (@c\u003c*\u003eword_embeddings) AS score\n    FROM words_table\n    ORDER BY score desc\n    LIMIT 3;",
      "outputs": [],
      "execution_count": 24
    },
    {
      "id": "99b34b0a",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## Clean up",
      "attachments": {}
    },
    {
      "id": "90b0773b",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eAction Required\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003e If you created a new database in your Standard or Premium Workspace, you can drop the database by running the cell below. Note: this will not drop your database for Free Starter Workspaces. To drop a Free Starter Workspace, terminate the Workspace using the UI. \u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "b4b02c5d",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "shared_tier_check = %sql show variables like 'is_shared_tier'\nif not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n    %sql DROP DATABASE IF EXISTS db_vector;",
      "outputs": [],
      "execution_count": 25
    },
    {
      "id": "cf2b8a2b",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"\u003e\u003c/div\u003e\n\u003cdiv\u003e\u003cimg src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/\u003e\u003c/div\u003e",
      "attachments": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimeType": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "singlestore_connection": {
      "connectionID": "",
      "defaultDatabase": ""
    },
    "singlestore_cell_default_language": "python"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
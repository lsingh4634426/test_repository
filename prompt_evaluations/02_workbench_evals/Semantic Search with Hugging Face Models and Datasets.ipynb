{
  "cells": [
    {
      "id": "0dcd1169",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-header\" style=\"display: flex; background-color: rgba(210, 255, 153, 0.25); padding: 5px;\"\u003e\n    \u003cdiv id=\"icon-image\" style=\"width: 90px; height: 90px;\"\u003e\n        \u003cimg width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/chart-network.png\" /\u003e\n    \u003c/div\u003e\n    \u003cdiv id=\"text\" style=\"padding: 5px; margin-left: 10px;\"\u003e\n        \u003cdiv id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\"\u003eSingleStore Notebooks\u003c/div\u003e\n        \u003ch1 style=\"font-weight: 500; margin: 8px 0 0 4px;\"\u003eSemantic Search with Hugging Face Models and Datasets\u003c/h1\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "8eaf13ef",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eNote\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003eThis notebook can be run on a Free Starter Workspace. To create a Free Starter Workspace navigate to \u003ctt\u003eStart\u003c/tt\u003e using the left nav. You can also use your existing Standard or Premium workspace with this Notebook.\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "8930a289",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "In this notebook, we will demonstrate an example of conducting semantic search on SingleStoreDB with SQL! Unlike traditional keyword-based search methods, semantic search algorithms take into account the relationships between words and their meanings, enabling them to deliver more accurate and relevant results – even when search terms are vague or ambiguous.\n\nSingleStoreDB’s built-in parallelization and Intel SIMD-based vector processing takes care of the heavy lifting involved in processing vector data. This allows your to run your ML algorithms right in your database extremely efficiently with just 1 line of SQL!\n\nIn this example, we use Hugging Face to create embeddings for our dataset and run semantic_search using dot_product vector matching function!",
      "attachments": {}
    },
    {
      "id": "377e3866",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 1. Create a workspace in your workspace group\n\nS-00 is sufficient.\n\n\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eAction Required\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003e If you have a Free Starter Workspace deployed already, select the database from drop-down menu at the top of this notebook. It updates the \u003ctt\u003econnection_url\u003c/tt\u003e to connect to that database.\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e\n\n## 2. Create a database named `semantic_search`",
      "attachments": {}
    },
    {
      "id": "989af2dd",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "shared_tier_check = %sql show variables like 'is_shared_tier'\nif not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n    %sql DROP DATABASE IF EXISTS semantic_search;\n    %sql CREATE DATABASE semantic_search;",
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "4f648058",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eAction Required\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003eMake sure to select the \u003ctt\u003esemantic_search\u003c/tt\u003e database from the drop-down menu at the top of this notebook.\n        It updates the \u003ctt\u003econnection_url\u003c/tt\u003e which is used by the \u003ctt\u003e%%sql\u003c/tt\u003e magic command and SQLAlchemy to make connections to the selected database.\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "f39d4c0d",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 3. Install and import required libraries\n\nWe will use an embedding model on Hugging Face with Sentence Transfomers library. We will be analysing the sentiment of reviewers of selected movies. This dataset is available on Hugging Face and to use it, we will need the datasets library.\n\nThe install process may take a couple minutes.",
      "attachments": {}
    },
    {
      "id": "7c20b03d",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%pip install sentence-transformers==2.2.2 torch==2.1.0 tensorflow==2.15.0 datasets==2.15.0 --quiet\n\nimport json\nimport ibis\nimport numpy as np\nimport pandas as pd\nimport sqlalchemy as sa\nimport singlestoredb as s2\nimport torch\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel",
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "1304a356",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 4. Load Sentence Transformer library and create a function called `get_embedding()`\n\nTo vectorize and embed the reviews that watchers of the movies left, we will be using the `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` model. We will create a function called `get_embedding()` that will call this model and return the vectorized version of the sentence.",
      "attachments": {}
    },
    {
      "id": "c67a6fb3",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "# Load Sentence Transformers model\nmodel_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n\nmodel = AutoModel.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)",
      "outputs": [],
      "execution_count": 3
    },
    {
      "id": "faaa17e1",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Add a function to compute the embedding. The result will be a numpy array of 32-bit floats.",
      "attachments": {}
    },
    {
      "id": "63effe1c",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "def get_embedding(sentence: str) -\u003e np.ndarray[np.float32]:\n    \"\"\"Retrieve embedding for given sentence.\"\"\"\n    inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\")\n    with torch.no_grad():\n        embedding = model(**inputs).last_hidden_state.mean(dim=1).squeeze().tolist()\n    return np.array(embedding, dtype='\u003cf4')",
      "outputs": [],
      "execution_count": 4
    },
    {
      "id": "d3092600",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 5. Load the dataset on movie reviews from Hugging Face into a `DataFrame`\n\nWe will be doing some operations and only sampling 100 random reviews from the \"test\" dataset of `imdb-movie-reviews`.",
      "attachments": {}
    },
    {
      "id": "fcfaf2f0",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "# Load the dataset into a pandas DataFrame\ndataset = load_dataset(\"ajaykarthick/imdb-movie-reviews\")\ndataframe = dataset[\"train\"].to_pandas()\n\nsample_size = 100  # Adjust the desired sample size\nrandom_sample = dataframe.sample(n=sample_size)",
      "outputs": [],
      "execution_count": 5
    },
    {
      "id": "d302c2b7",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 6. Generate embeddings of the reviews left by customers and add them to your `DataFrame`\n\nWe want to embed the entries in the `review` column and add the embeddings to the data. We will do this with pandas and our `get_embeddings` function. Embeddings are stored as a numpy array.",
      "attachments": {}
    },
    {
      "id": "f7286972",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "random_sample['review_embeddings'] = random_sample['review'].apply(get_embedding)",
      "outputs": [],
      "execution_count": 6
    },
    {
      "id": "d49f2a7c",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 7. Insert data into SingleStoreDB\n\nYou can seamlessly bring this data to your SingleStoreDB table directly from your from `DataFrame`. SingleStore ♥️ Python.\n\nWe will bring this data into a table called `reviews`. Notice how you don't have to write any SQL for this – we will infer the schema from your `DataFrame` and underneath the hood configure how to bring this `DataFrame` into our database. Since numpy arrays don't map directly to a database type, we give pandas a type hint to create a blob column for the `review_embeddings` column.",
      "attachments": {}
    },
    {
      "id": "333f4afa",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "random_sample.to_sql('reviews',\n                     s2.create_engine().connect(),\n                     if_exists='replace',\n                     index=False,\n                     dtype=dict(review_embeddings=sa.LargeBinary))",
      "outputs": [],
      "execution_count": 7
    },
    {
      "id": "4d133dc2",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "# Create a database connection and display the `CREATE TABLE` statement\nconn = s2.connect()\n\nconn.show.create_table('reviews')",
      "outputs": [],
      "execution_count": 8
    },
    {
      "id": "371ad41b",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 8. Run the semantic search algorithm with just one line of SQL\n\nWe will utilize SingleStoreDB's distributed architecture to efficiently compute the dot product of the input string (stored in searchstring) with each entry in the database and return the top 5  reviews with the highest dot product score. Each vector is normalized to length 1, hence the dot product function essentially computes the cosine similarity between two vectors – an appropriate nearness metric. SingleStoreDB makes this extremely fast because it compiles queries to machine code and runs dot_product using SIMD instructions.",
      "attachments": {}
    },
    {
      "id": "2599d1bf",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "searchstring = input('Please enter a search string:')\n\nsearch_embedding = get_embedding(searchstring).tobytes().hex()\n\nresults = %sql SELECT review, DOT_PRODUCT(review_embeddings, X'{{search_embedding}}') AS Score \\\n               FROM reviews ORDER BY Score DESC LIMIT 5;\n\nprint()\nfor i, res in enumerate(results):\n    print(f'{i + 1}: {res[0]} Score: {res[1]:.2f}\\n')",
      "outputs": [],
      "execution_count": 9
    },
    {
      "id": "cc466e92",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 9. Clean up",
      "attachments": {}
    },
    {
      "id": "fc8b28e8",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eAction Required\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003e If you created a new database in your Standard or Premium Workspace, you can drop the database by running the cell below. Note: this will not drop your database for Free Starter Workspaces. To drop a Free Starter Workspace, terminate the Workspace using the UI. \u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "10aae5a1",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "shared_tier_check = %sql show variables like 'is_shared_tier'\nif not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n    %sql DROP DATABASE IF EXISTS semantic_search;",
      "outputs": [],
      "execution_count": 10
    },
    {
      "id": "60d17a89",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"\u003e\u003c/div\u003e\n\u003cdiv\u003e\u003cimg src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/\u003e\u003c/div\u003e",
      "attachments": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimeType": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "singlestore_connection": {
      "connectionID": "",
      "defaultDatabase": ""
    },
    "singlestore_cell_default_language": "python"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
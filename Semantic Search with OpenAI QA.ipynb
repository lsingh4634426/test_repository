{
  "cells": [
    {
      "id": "67480459",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-header\" style=\"display: flex; background-color: rgba(255, 167, 103, 0.25); padding: 5px;\"\u003e\n    \u003cdiv id=\"icon-image\" style=\"width: 90px; height: 90px;\"\u003e\n        \u003cimg width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/crystal-ball.png\" /\u003e\n    \u003c/div\u003e\n    \u003cdiv id=\"text\" style=\"padding: 5px; margin-left: 10px;\"\u003e\n        \u003cdiv id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\"\u003eSingleStore Notebooks\u003c/div\u003e\n        \u003ch1 style=\"font-weight: 500; margin: 8px 0 0 4px;\"\u003eSemantic Search with OpenAI QA\u003c/h1\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "09632a57",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eNote\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003eThis notebook can be run on a Free Starter Workspace. To create a Free Starter Workspace navigate to \u003ctt\u003eStart\u003c/tt\u003e using the left nav. You can also use your existing Standard or Premium workspace with this Notebook.\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "5887cda1",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "In this Notebook you will use a combination of Semantic Search and a Large Langauge Model (LLM) to build a basic Retrieval Augmented Generation (RAG) application. For a great introduction into what RAG is, please read [A Beginner's Guide to Retrieval Augmented Generation (RAG)](https://www.singlestore.com/blog/a-guide-to-retrieval-augmented-generation-rag/).\n## Prerequisites for interacting with ChatGPT",
      "attachments": {}
    },
    {
      "id": "d55d2aa8",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "### Install OpenAI package\n\nLet's start by installing the [openai](https://platform.openai.com/docs/api-reference?lang=python) Python package.",
      "attachments": {}
    },
    {
      "id": "297675eb",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "!pip install openai==1.3.3 --quiet",
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "37988f8c",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "### Connect to ChatGPT and display the response",
      "attachments": {}
    },
    {
      "id": "60318fb1",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import openai\n\nEMBEDDING_MODEL = \"text-embedding-ada-002\"\nGPT_MODEL = \"gpt-3.5-turbo\"",
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "44c80931",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "You will need an OpenAI API key in order to use the the `openai` Python library.",
      "attachments": {}
    },
    {
      "id": "603fbac4",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import getpass\nimport os\n\nos.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key: ')\n\nclient = openai.OpenAI()",
      "outputs": [],
      "execution_count": 3
    },
    {
      "id": "a29c90d9",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Test the connection.",
      "attachments": {}
    },
    {
      "id": "23d11168",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "response = client.chat.completions.create(\n  model=GPT_MODEL,\n  messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Who won the gold medal for curling in Olymics 2022?\"},\n    ]\n)\n\nprint(response.choices[0].message.content)",
      "outputs": [],
      "execution_count": 4
    },
    {
      "id": "2363818e",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "# Get the data about Winter Olympics and provide the information to ChatGPT as context",
      "attachments": {}
    },
    {
      "id": "98ab17e2",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 1. Install and import libraries",
      "attachments": {}
    },
    {
      "id": "9a18969c",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "!pip install tabulate tiktoken wget --quiet",
      "outputs": [],
      "execution_count": 5
    },
    {
      "id": "a4a0ba11",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import json\nimport numpy as np\nimport os\nimport pandas as pd\nimport wget",
      "outputs": [],
      "execution_count": 6
    },
    {
      "id": "ce88a189",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 2. Fetch the CSV data and read it into a DataFrame",
      "attachments": {}
    },
    {
      "id": "ee0738ce",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Download pre-chunked text and pre-computed embeddings. This file is ~200 MB, so may take a minute depending on your connection speed.",
      "attachments": {}
    },
    {
      "id": "bdfd15f0",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "embeddings_url = \"https://cdn.openai.com/API/examples/data/winter_olympics_2022.csv\"\nembeddings_path = \"winter_olympics_2022.csv\"\n\nif not os.path.exists(embeddings_path):\n    wget.download(embeddings_url, embeddings_path)\n    print(\"File downloaded successfully.\")\nelse:\n    print(\"File already exists in the local file system.\")",
      "outputs": [],
      "execution_count": 7
    },
    {
      "id": "66a2c515",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Here we are using the `converters=` parameter of the `pd.read_csv` function to convert the JSON\narray in the CSV file to numpy arrays.",
      "attachments": {}
    },
    {
      "id": "1956ecc7",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "def json_to_numpy_array(x: str | None) -\u003e np.ndarray | None:\n    \"\"\"Convert JSON array string into numpy array.\"\"\"\n    return np.array(json.loads(x)) if x else None\n\ndf = pd.read_csv(embeddings_path, converters=dict(embedding=json_to_numpy_array))\ndf",
      "outputs": [],
      "execution_count": 8
    },
    {
      "id": "7b0569fd",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "df.info(show_counts=True)",
      "outputs": [],
      "execution_count": 9
    },
    {
      "id": "e5f60bd0",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 3. Set up the database",
      "attachments": {}
    },
    {
      "id": "43947d3d",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eAction Required\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003e If you have a Free Starter Workspace deployed already, select the database from drop-down menu at the top of this notebook. It updates the \u003ctt\u003econnection_url\u003c/tt\u003e to connect to that database.\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "3f1baf5b",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Create the database.",
      "attachments": {}
    },
    {
      "id": "4f789d23",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "shared_tier_check = %sql show variables like 'is_shared_tier'\nif not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n    %sql DROP DATABASE IF EXISTS winter_wikipedia;\n    %sql CREATE DATABASE winter_wikipedia;",
      "outputs": [],
      "execution_count": 10
    },
    {
      "id": "a5fd7f34",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eAction Required\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003eMake sure to select the \u003ctt\u003ewinter_wikipedia\u003c/tt\u003e database from the drop-down menu at the top of this notebook.\n        It updates the \u003ctt\u003econnection_url\u003c/tt\u003e which is used by the \u003ctt\u003e%%sql\u003c/tt\u003e magic command and SQLAlchemy to make connections to the selected database.\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "a6cbcb7e",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "%%sql\nCREATE TABLE IF NOT EXISTS winter_olympics_2022 /* Creating table for sample data. */(\n    id INT PRIMARY KEY,\n    text TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci,\n    embedding BLOB\n);",
      "outputs": [],
      "execution_count": 11
    },
    {
      "id": "4dedda5c",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 4. Populate the table with our DataFrame",
      "attachments": {}
    },
    {
      "id": "cae0a395",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Create a SQLAlchemy connection.",
      "attachments": {}
    },
    {
      "id": "dba9a833",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import singlestoredb as s2\n\nconn = s2.create_engine().connect()",
      "outputs": [],
      "execution_count": 12
    },
    {
      "id": "490ccfe3",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "Use the `to_sql` method of the DataFrame to upload the data to the requested table.",
      "attachments": {}
    },
    {
      "id": "1360d505",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "df.to_sql('winter_olympics_2022', con=conn, index=True, index_label='id', if_exists='append', chunksize=1000)",
      "outputs": [],
      "execution_count": 13
    },
    {
      "id": "8ea4a8eb",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## 5. Do a semantic search with the same question from above and use the response to send to OpenAI again",
      "attachments": {}
    },
    {
      "id": "a147f99c",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import sqlalchemy as sa\n\n\ndef get_embedding(text: str, model: str = 'text-embedding-ada-002') -\u003e str:\n    \"\"\"Return the embeddings.\"\"\"\n    return [x.embedding for x in client.embeddings.create(input=[text], model=model).data][0]\n\n\ndef strings_ranked_by_relatedness(\n    query: str,\n    df: pd.DataFrame,\n    table_name: str,\n    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n    top_n: int=100,\n) -\u003e tuple:\n    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n\n    # Get the embedding of the query.\n    query_embedding_response = get_embedding(query, EMBEDDING_MODEL)\n\n    # Create the SQL statement.\n    stmt = sa.text(f\"\"\"\n        SELECT\n            text,\n            DOT_PRODUCT_F64(JSON_ARRAY_PACK_F64(:embedding), embedding) AS score\n        FROM {table_name}\n        ORDER BY score DESC\n        LIMIT :limit\n    \"\"\")\n\n    # Execute the SQL statement.\n    results = conn.execute(stmt, dict(embedding=json.dumps(query_embedding_response), limit=top_n))\n\n    strings = []\n    relatednesses = []\n\n    for row in results:\n        strings.append(row[0])\n        relatednesses.append(row[1])\n\n    # Return the results.\n    return strings[:top_n], relatednesses[:top_n]",
      "outputs": [],
      "execution_count": 14
    },
    {
      "id": "a8edab89",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "from tabulate import tabulate\n\nstrings, relatednesses = strings_ranked_by_relatedness(\n    \"curling gold medal\",\n    df,\n    \"winter_olympics_2022\",\n    top_n=5\n)\n\nfor string, relatedness in zip(strings, relatednesses):\n    print(f\"{relatedness=:.3f}\")\n    print(tabulate([[string]], headers=['Result'], tablefmt='fancy_grid'))\n    print('\\n\\n')",
      "outputs": [],
      "execution_count": 15
    },
    {
      "id": "231acb2b",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import tiktoken\n\n\ndef num_tokens(text: str, model: str=GPT_MODEL) -\u003e int:\n    \"\"\"Return the number of tokens in a string.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    return len(encoding.encode(text))\n\n\ndef query_message(\n    query: str,\n    df: pd.DataFrame,\n    model: str,\n    token_budget: int\n) -\u003e str:\n    \"\"\"Return a message for GPT, with relevant source texts pulled from SingleStoreDB.\"\"\"\n    strings, relatednesses = strings_ranked_by_relatedness(query, df, \"winter_olympics_2022\")\n    introduction = 'Use the below articles on the 2022 Winter Olympics to answer the subsequent question. If the answer cannot be found in the articles, write \"I could not find an answer.\"'\n    question = f\"\\n\\nQuestion: {query}\"\n    message = introduction\n    for string in strings:\n        next_article = f'\\n\\nWikipedia article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n        if (\n            num_tokens(message + next_article + question, model=model)\n            \u003e token_budget\n        ):\n            break\n        else:\n            message += next_article\n    return message + question\n\n\ndef ask(\n    query: str,\n    df: pd.DataFrame=df,\n    model: str=GPT_MODEL,\n    token_budget: int=4096 - 500,\n    print_message: bool=False,\n) -\u003e str:\n    \"\"\"Answers a query using GPT and a table of relevant texts and embeddings in SingleStoreDB.\"\"\"\n    message = query_message(query, df, model=model, token_budget=token_budget)\n    if print_message:\n        print(message)\n    messages = [\n        {\"role\": \"system\", \"content\": \"You answer questions about the 2022 Winter Olympics.\"},\n        {\"role\": \"user\", \"content\": message},\n    ]\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=0\n    )\n    response_message = response.choices[0].message.content\n    return response_message",
      "outputs": [],
      "execution_count": 16
    },
    {
      "id": "cda561e4",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "print(ask('Who won the gold medal for curling in Olymics 2022?'))",
      "outputs": [],
      "execution_count": 17
    },
    {
      "id": "77dde827",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "## Clean up",
      "attachments": {}
    },
    {
      "id": "750bbd14",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eAction Required\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003e If you created a new database in your Standard or Premium Workspace, you can drop the database by running the cell below. Note: this will not drop your database for Free Starter Workspaces. To drop a Free Starter Workspace, terminate the Workspace using the UI. \u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "dd07be8d",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "shared_tier_check = %sql show variables like 'is_shared_tier'\nif not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n    %sql DROP DATABASE IF EXISTS winter_wikipedia;",
      "outputs": [],
      "execution_count": 18
    },
    {
      "id": "2a95146c",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"\u003e\u003c/div\u003e\n\u003cdiv\u003e\u003cimg src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/\u003e\u003c/div\u003e",
      "attachments": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimeType": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "singlestore_connection": {
      "connectionID": "",
      "defaultDatabase": ""
    },
    "singlestore_cell_default_language": "python"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
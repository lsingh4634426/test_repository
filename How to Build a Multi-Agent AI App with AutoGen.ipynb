{
  "cells": [
    {
      "id": "41c70e1c",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-header\" style=\"display: flex; background-color: rgba(209, 153, 255, 0.25); padding: 5px;\"\u003e\n    \u003cdiv id=\"icon-image\" style=\"width: 90px; height: 90px;\"\u003e\n        \u003cimg width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/vector-circle.png\" /\u003e\n    \u003c/div\u003e\n    \u003cdiv id=\"text\" style=\"padding: 5px; margin-left: 10px;\"\u003e\n        \u003cdiv id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\"\u003eSingleStore Notebooks\u003c/div\u003e\n        \u003ch1 style=\"font-weight: 500; margin: 8px 0 0 4px;\"\u003eHow to Build a Multi-Agent AI App with AutoGen\u003c/h1\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "1c6aa139",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n    \u003cb class=\"fa fa-solid fa-exclamation-circle\"\u003e\u003c/b\u003e\n    \u003cdiv\u003e\n        \u003cp\u003e\u003cb\u003eNote\u003c/b\u003e\u003c/p\u003e\n        \u003cp\u003eThis notebook can be run on a Free Starter Workspace. To create a Free Starter Workspace navigate to \u003ctt\u003eStart\u003c/tt\u003e using the left nav. You can also use your existing Standard or Premium workspace with this Notebook.\u003c/p\u003e\n    \u003c/div\u003e\n\u003c/div\u003e",
      "attachments": {}
    },
    {
      "id": "4ab9a0e9",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "# Python Notebook Introduction\n\nThis Jupyter notebook is designed to demonstrate the use of various Python libraries for text processing, document loading, and vector embeddings. It also showcases the use of the OpenAI API for generating embeddings and the SingleStoreDB for storing and retrieving documents.\n\nThe notebook is divided into several sections:\n\n1. **Installation of Required Libraries**: This section covers the installation of necessary libraries such as `langchain_community`, `pyautogen`, `langchain_openai`, `langchain_text_splitters`, and `unstructured`.\n\n2. **Data Loading and Preparation**: This section involves loading a markdown document from a URL and preparing it for further processing.\n\n3. **Document Splitting and Embedding Generation**: This section demonstrates how to split the loaded document into smaller parts and generate embeddings for each part using the OpenAI API.\n\n4. **SingleStoreDB Setup**: This section covers the setup of SingleStoreDB for storing and retrieving documents.\n\n5. **Agent Setup and Group Chat Simulation**: This section demonstrates the setup of various agents (like a boss, coder, product manager, and code reviewer) and simulates a group chat among them to solve a given problem.\n\n6. **Chat Simulation**: This section runs the chat simulation without and with the Retrieve and Generate (RAG) model.\n\nPlease ensure that you have the necessary API keys and environment variables set up before running this notebook.",
      "attachments": {}
    },
    {
      "id": "cac05073",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "# Check if the database is running on a shared tier\nshared_tier_check = %sql show variables like 'is_shared_tier'\n\n# If not on a shared tier, or if the shared tier is turned off, drop the existing database and create a new one\nif not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n    %sql DROP DATABASE IF EXISTS autogen\n    %sql CREATE DATABASE autogen",
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "8d379d39",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "!pip install --quiet langchain_community pyautogen langchain_openai langchain_text_splitters unstructured",
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "9971496f",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "!pip install --quiet markdown",
      "outputs": [],
      "execution_count": 3
    },
    {
      "id": "ea22b9ad",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import requests\n\nr = requests.get(\"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Examples/Integrate%20-%20Spark.md\")\nopen('example.md', 'wb').write(r.content)",
      "outputs": [],
      "execution_count": 4
    },
    {
      "id": "f72ca06c",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "from langchain_community.vectorstores import SingleStoreDB\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_community.document_loaders import UnstructuredMarkdownLoader\nfrom langchain_text_splitters import CharacterTextSplitter\nfrom typing import List, Dict, Union\nimport os\n\nloader = UnstructuredMarkdownLoader(\"./example.md\")\n\nos.environ[\"OPENAI_API_KEY\"] = \"api-key\"\n\ndata = loader.load()\n\ntext_splitter = CharacterTextSplitter()\n\ndocs = text_splitter.split_documents(data)\n\nembeddings = OpenAIEmbeddings()\n\nos.environ[\"SINGLESTOREDB_URL\"] = \"admin:pass@host:3306/db\"",
      "outputs": [],
      "execution_count": 5
    },
    {
      "id": "3c0ab2a6",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "singlestore_db = SingleStoreDB.from_documents(\n    docs,\n    embeddings,\n    table_name=\"notebook2\",  # use table with a custom name\n)",
      "outputs": [],
      "execution_count": 6
    },
    {
      "id": "9042b951",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "!pip install --quiet pyautogen[retrievechat]",
      "outputs": [],
      "execution_count": 7
    },
    {
      "id": "50418505",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import autogen\nfrom autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\nfrom autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\nfrom autogen import config_list_from_json\nfrom autogen import AssistantAgent",
      "outputs": [],
      "execution_count": 8
    },
    {
      "id": "e2e53553",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "class SingleStoreRetrieveUserProxyAgent(RetrieveUserProxyAgent):\n    def __init__(self, singlestore_db: SingleStoreDB, **kwargs):\n        super().__init__(**kwargs)\n        self.singlestore_db = singlestore_db\n\n    def query_vector_db(\n        self,\n        query_texts: List[str],\n        n_results: int = 10,\n        search_string: str = \"\",\n        **kwargs,\n    ) -\u003e Dict[str, List[List[str]]]:\n        documents = []\n        ids = []\n        for query_index, query_text in enumerate(query_texts):\n            searched_docs = self.singlestore_db.similarity_search(\n                query=query_text,\n                k=n_results,\n            )\n            # Assuming searched_docs is a list of documents with only 'page_content' property\n            batch_documents = [doc.page_content for doc in searched_docs]\n            documents.append(batch_documents)\n\n            # Generate a unique ID for each document based on enumeration\n            batch_ids = [f\"{query_index}-{i}\" for i in range(len(batch_documents))]\n            ids.append(batch_ids)\n\n        return {\n            \"ids\": ids,\n            \"documents\": documents,\n        }\n\n    def retrieve_docs(self, problem: str, n_results: int = 20, search_string: str = \"\", **kwargs):\n        results = self.query_vector_db(\n            query_texts=[problem],\n            n_results=n_results,\n            search_string=search_string,\n            **kwargs,\n        )\n\n        self._results = results",
      "outputs": [],
      "execution_count": 9
    },
    {
      "id": "8f7e260a",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "import os\nos.environ[\"AUTOGEN_USE_DOCKER\"] = \"False\"",
      "outputs": [],
      "execution_count": 10
    },
    {
      "id": "e34f343a",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "llm_config = {\n    \"config_list\": [{\"model\": \"gpt-3.5-turbo\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}],\n    }\n\ndef termination_msg(x):\n    return isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()\n\n\nboss = autogen.UserProxyAgent(\n    name=\"Boss\",\n    is_termination_msg=termination_msg,\n    human_input_mode=\"NEVER\",\n    code_execution_config=False,  # we don't want to execute code in this case.\n    default_auto_reply=\"Reply `TERMINATE` if the task is done.\",\n    description=\"The boss who ask questions and give tasks.\",\n)\n\nboss_aid = SingleStoreRetrieveUserProxyAgent(\n    name=\"Boss_Assistant\",\n    is_termination_msg=termination_msg,\n    human_input_mode=\"NEVER\",\n    max_consecutive_auto_reply=3,\n    retrieve_config={\n        \"task\": \"code\",\n    },\n    code_execution_config=False,  # we don't want to execute code in this case.\n    description=\"Assistant who has extra content retrieval power for solving difficult problems.\",\n    singlestore_db=singlestore_db\n)\n\ncoder = autogen.AssistantAgent(\n    name=\"Senior_Python_Engineer\",\n    is_termination_msg=termination_msg,\n    system_message=\"You are a senior python engineer, you provide python code to answer questions. Reply `TERMINATE` in the end when everything is done.\",\n    llm_config=llm_config,\n    description=\"Senior Python Engineer who can write code to solve problems and answer questions.\",\n)\n\npm = autogen.AssistantAgent(\n    name=\"Product_Manager\",\n    is_termination_msg=termination_msg,\n    system_message=\"You are a product manager. Reply `TERMINATE` in the end when everything is done.\",\n    llm_config=llm_config,\n    description=\"Product Manager who can design and plan the project.\",\n)\n\nreviewer = autogen.AssistantAgent(\n    name=\"Code_Reviewer\",\n    is_termination_msg=termination_msg,\n    system_message=\"You are a code reviewer. Reply `TERMINATE` in the end when everything is done.\",\n    llm_config=llm_config,\n    description=\"Code Reviewer who can review the code.\",\n)\n\nPROBLEM = \"How to use spark for parallel training in FLAML? Give me sample code.\"\n\n\ndef _reset_agents():\n    boss.reset()\n    boss_aid.reset()\n    coder.reset()\n    pm.reset()\n    reviewer.reset()\n\n\ndef rag_chat():\n    _reset_agents()\n    groupchat = autogen.GroupChat(\n        agents=[boss_aid, pm, coder, reviewer], messages=[], max_round=12, speaker_selection_method=\"round_robin\"\n    )\n    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n\n    # Start chatting with boss_aid as this is the user proxy agent.\n    boss_aid.initiate_chat(\n        manager,\n        problem=PROBLEM,\n        n_results=3,\n    )\n\n\ndef norag_chat():\n    _reset_agents()\n    groupchat = autogen.GroupChat(\n        agents=[boss, pm, coder, reviewer],\n        messages=[],\n        max_round=12,\n        speaker_selection_method=\"auto\",\n        allow_repeat_speaker=False,\n    )\n    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n\n    # Start chatting with the boss as this is the user proxy agent.\n    boss.initiate_chat(\n        manager,\n        message=PROBLEM,\n    )\n\n\ndef call_rag_chat():\n    _reset_agents()\n\n    # In this case, we will have multiple user proxy agents and we don't initiate the chat\n    # with RAG user proxy agent.\n    # In order to use RAG user proxy agent, we need to wrap RAG agents in a function and call\n    # it from other agents.\n    def retrieve_content(\n        message: Annotated[\n            str,\n            \"Refined message which keeps the original meaning and can be used to retrieve content for code generation and question answering.\",\n        ],\n        n_results: Annotated[int, \"number of results\"] = 3,\n    ) -\u003e str:\n        boss_aid.n_results = n_results  # Set the number of results to be retrieved.\n        # Check if we need to update the context.\n        update_context_case1, update_context_case2 = boss_aid._check_update_context(message)\n        if (update_context_case1 or update_context_case2) and boss_aid.update_context:\n            boss_aid.problem = message if not hasattr(boss_aid, \"problem\") else boss_aid.problem\n            _, ret_msg = boss_aid._generate_retrieve_user_reply(message)\n        else:\n            ret_msg = boss_aid.generate_init_message(message, n_results=n_results)\n        return ret_msg if ret_msg else message\n\n    boss_aid.human_input_mode = \"NEVER\"  # Disable human input for boss_aid since it only retrieves content.\n\n    for caller in [pm, coder, reviewer]:\n        d_retrieve_content = caller.register_for_llm(\n            description=\"retrieve content for code generation and question answering.\", api_style=\"function\"\n        )(retrieve_content)\n\n    for executor in [boss, pm]:\n        executor.register_for_execution()(d_retrieve_content)\n\n    groupchat = autogen.GroupChat(\n        agents=[boss, pm, coder, reviewer],\n        messages=[],\n        max_round=12,\n        speaker_selection_method=\"round_robin\",\n        allow_repeat_speaker=False,\n    )\n\n    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n\n    # Start chatting with the boss as this is the user proxy agent.\n    boss.initiate_chat(\n        manager,\n        message=PROBLEM,\n    )",
      "outputs": [],
      "execution_count": 11
    },
    {
      "id": "98387dfd",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "norag_chat()",
      "outputs": [],
      "execution_count": 12
    },
    {
      "id": "bec4ada5",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "rag_chat()",
      "outputs": [],
      "execution_count": 13
    },
    {
      "id": "1b379204",
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "language": "python"
      },
      "source": "shared_tier_check = %sql show variables like 'is_shared_tier'\nif not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n    %sql DROP DATABASE IF EXISTS autogen",
      "outputs": [],
      "execution_count": 14
    },
    {
      "id": "083eef58",
      "cell_type": "markdown",
      "metadata": {
        "execution": {}
      },
      "source": "\u003cdiv id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"\u003e\u003c/div\u003e\n\u003cdiv\u003e\u003cimg src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/\u003e\u003c/div\u003e",
      "attachments": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimeType": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "jupyterlab": {
      "notebooks": {
        "version_major": 6,
        "version_minor": 4
      }
    },
    "singlestore_connection": {
      "connectionID": "",
      "defaultDatabase": ""
    },
    "singlestore_cell_default_language": "python"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}